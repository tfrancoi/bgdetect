\documentclass[11pt,a4paper]{report}
\usepackage{ifpdf}
\usepackage[utf8]{inputenc}
\usepackage[francais]{babel}
\usepackage[pdftex]{graphicx}
\usepackage{listings}
\usepackage{array}


\title{ELEC 2885 : Image processing and computer  \\ Project \\
Benoit Macq \\ Christophe Devleeschouwer \\ Antonin Descampe}
\author{Thibault François \\ Frédéric Vand der Essen}
\date{\today}



\begin{document}
	\begin{titlepage}		
		\begin{figure}[tbp]
			\begin{center}
				\includegraphics{image/logo.png}
			\end{center}
		\end{figure}
		\maketitle
	\end{titlepage}

\section{Introduction}
Dans ce projet nous essayons de séparer les éléments du background de ceux du foreground. Nous définissons le background comme les éléments du décors
qui ne bouge pas, par conséquent notre technique ne fonctionnera qu'avec des images prises d'une caméra fixe. 

\section{Features extractions}
L'approche par arbres aléatoire permet de classer les pixels selon plusieurs critères. Ils nous faut donc dans un premier temps définir ces critères. La première feature est l'intensité du pixel, c'est à dire la moyenne des trois composants RGB. Nous avons extrait deux autres features le gradient de l'intensité selon l'horizontale et selon la verticale \cite{gradient} grâce à l'opérateur de convolution de Sobel \cite{sobel}. Nous chargons les images grâce à la bibliothèque \textit{PIL} (Python Image Library). Cette api nous donne un tuple contenant les composantes RBG de l'image pour chaque pixel. L'intensité ce calcul directement et pour la gradient les détails de l'implémentation se trouve dans le fichier \textit{jpg.py} dans la fonction \textit{g()} et les tables des hash \textit{x} et \textit{y} correspondent aux matrices de convolution.  


\section{Random Forest classification}

\section{Tuning des paramètres}
Il y a de nombreux paramètres à mettre aux points. Il y a trop de paramètres différents pour pouvoir tous les comparés, nous avons donc travailler à trouver l'optimal pour un paramètre à la fois. 

Dans un premier temps, savoir quelle features choisir, nous avons effectués des tests avec juste l'intensité et ensuite avec l'intensité et les deux gradients. 

\% Gradient est une bonne idée

Dans un second temps, la quantité d'arbre aléatoire utilisé pour classifié peut-être choisie. Ici, il faut trouver le juste milieu entre trop d'arbres qui consommerait beaucoup de temps de calcul et pas assez qui ne serait pas assez précis.

La profondeur des arbres est encore un paramètre à déterminer, nous aurions pu décider d'arrêter la profondeur de l'arbre lorsque la découpe des bornes serait suffissante mais il aurait quand même fallut déterminer ``la découpe suffisante''. Nous avons donc choisit de définir nous même la profondeur de l'arbre. Une trop grande profondeur n'est pas forcément souhaitable pour les résultats et est toujours synonimes de plus de calcul, trop peu de profondeur ne permet pas non plus une bonne classification. Par défault nous utilisons une profondeur de 8 pour 3 features. La profondeur des arbres idéale est liée au.

-> Choix heuristique de classification (moyenne / densité)  ok 
-> Nombre d'arbre sélection
-> Decision finale (\% de vote)

\section{Resultat}

\section{Conclusion}
	
	
\section{Bibliographie}	
\begin{thebibliography}{2}
   \bibitem{gradient} http://en.wikipedia.org/wiki/Image\_gradient
   \bibitem{sobel} http://en.wikipedia.org/wiki/Sobel\_operator
  
\end{thebibliography}








\end{document}
